# -*- coding: utf-8 -*-
"""Lab04_pandas_gpt.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1brXai16VMhWu_stEhpKekyDR-vwdkq7M

<a href="https://colab.research.google.com/github/hernansalinas/autogrades/blob/main/Laboratorios_Taller/Lab04_pandas_gpt.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

### Pandas y chat gpt

Comandos basicos de pandas:


| Function | Description |
| --- | --- |
| `fillna()` | Replace NaN values in a DataFrame or Series with a specified value. |
| `dropna()` | Remove rows or columns containing NaN values from a DataFrame. |
| `loc[]` | Select rows and columns from a DataFrame by label-based indexing. |
| `iloc[]` | Select rows and columns from a DataFrame by integer-based indexing. |
| `[]` | Select a single column from a DataFrame using dot notation or bracket notation. |
| `shape` | Get the number of rows and columns in a DataFrame. |
| `dtypes` | Get the data types of the columns in a DataFrame. |
| `head()` | Get the first n rows of a DataFrame. |
| `tail()` | Get the last n rows of a DataFrame. |
| `describe()` | Get summary statistics for the columns in a DataFrame. |
| `groupby()` | Group a DataFrame by one or more columns and perform an aggregation. |
| `sort_values()` | Sort a DataFrame by one or more columns. |
| `merge()` | Merge two DataFrames on a common column. |
| `pivot_table()` | Create a pivot table from a DataFrame. |
| `to_csv()` | Save a DataFrame to a CSV file. |
| `read_csv()` | Read a CSV file into a DataFrame. |





# Problema 1
1. a) Generar un diccionario con CHATGPT con los premios nobel de fisica de la decada que tu elijas.  El diccionario debe tener la siguiente estructura:

clave: Nombre del cientifico, el nombre del cientifico se debe llamar de la siguiente forma: Inicial del nombre del cientifico y Apellido, ejemplo: A. Einstein., R. Feyman.

Valor: diccionario con el año y el motivo por que el gano el premio nobel resumido maximo 10 palabras.


b). Con el diccionario construir un dataframe de pandas y almacenarlo como un archivo csv. Las columnas del data frame se deberán llamar Cientifico, AnoNobel, Motivo.
"""

#Primer Punto: Generar el diccionario con chatgpt. (Década del 1900)
import pandas as pd
premiosNobel = {
    'W. Röntgen': {
        'año': 1901,
        'motivo': 'Por el descubrimiento de los rayos X, el cual ha sido de gran importancia para el desarrollo de la física y la medicina'
    },
    'H. Lorentz': {
        'año': 1902,
        'motivo': 'Por sus investigaciones sobre la influencia de los campos eléctricos y magnéticos en la radiación, lo que condujo a importantes avances en la teoría electromagnética'
    },
    'P. Zeeman': {
        'año': 1902,
        'motivo': 'Por el descubrimiento del efecto Zeeman, que demuestra la división de ciertas líneas espectrales bajo la influencia de un campo magnético'
    },
    'A. Becquerel': {
        'año': 1903,
        'motivo': 'Por el descubrimiento de la radiactividad natural'
    },
    'M. Curie': {
        'año': 1903,
        'motivo': 'En reconocimiento a sus estudios sobre la radioactividad descubierta por Becquerel, así como por su aislamiento de los elementos radio y polonio'
    },
    'H. Becquerel': {
        'año': 1903,
        'motivo': 'Por su descubrimiento de la radiactividad natural'
    },
    'Lord Rayleigh': {
        'año': 1904,
        'motivo': 'Por su investigación sobre la densidad de los gases y el descubrimiento del gas argón'
    },
    'J. Strutt (Lord Rayleigh)': {
        'año': 1904,
        'motivo': 'Por su investigación sobre la densidad de los gases y el descubrimiento del gas argón'
    },
    'P. Lenard': {
        'año': 1905,
        'motivo': 'Por sus investigaciones sobre los rayos catódicos, que condujeron a importantes avances en la comprensión de la naturaleza de la radiación'
    },
    'J.J. Thomson': {
        'año': 1906,
        'motivo': 'Por sus investigaciones sobre la conducción eléctrica en gases, así como por el descubrimiento del electrón'
    },
    'A.A. Michelson': {
        'año': 1907,
        'motivo': 'Por su precisión en la medición de la velocidad de la luz, lo que condujo a importantes avances en la teoría de la relatividad de Einstein'
    },
    'A. Einstein': {
        'año': 1905,
        'motivo': 'Por sus servicios a la física teórica, y en particular por su descubrimiento de la ley del efecto fotoeléctrico'
    },
    'G.L. Michelson': {
        'año': 1907,
        'motivo': 'Por su precisión en la medición de la velocidad de la luz, lo que condujo a importantes avances en la teoría de la relatividad de Einstein'
    }}

#Construir un dataframe con el diccionario.
df = pd.DataFrame(premiosNobel)
#Ojo al crear un dataframe a partir de otro, ambos apuntan a la misma posicion de memoria.
g = df.transpose().reset_index().copy()
#Cambiamos el nombre de la columna
g = g.rename(columns= {'index':'Cientifico','año':'AnoNobel','motivo':'Motivo'})
g
#EN data science se habla de registros, no de filas.

"""#Problema 2.

Usando el dataset `PS4_1.csv`, convertir la serie `Date` en el indice (serie de tiempo) y eliminar la serie `Unnamed: 1` (generado por pandas), retornar un  diccionario con en el siguiente orden:

* cantidad de columnas
* Nombre de las columnas
* número de registros no NaN de cada columna
* cantidad total de memoria usada para cargar el dataset en el computador ,( df.memory_usage() )
* Estadistica basica para cada columna, media, desviacion estandar, maximo
* Remplazar los NaN por None


```
import pandas as pd

df = pd.read_excel("dataset/PS4_1.xlsx")
for d in df.Date:
    if(type(d)==str):
        df["Date_"] = datetime.strptime(d, "%d/%m/%Y")
    else:
        df["Date_"]=d
df=df.set_index("Date_")
df=df.drop(columns=["Date","Unnamed: 1"])

```



"""

#Tomemos el link del excel desde drive.
import pandas as pd
url ='https://docs.google.com/spreadsheets/d/e/2PACX-1vQMfRjGspVzFho_P7HOFHaw0FaePpqM_ZBa5RC8uCwTuJRtPmkJ2uSgRUEpFrP9OQ/pub?output=xlsx'
df = pd.read_excel(url)
#Cambiemos la primera columna a datetime
from datetime import datetime
for d in df.Date:
    if(type(d)==str):
        df["Date_"] = datetime.strptime(d, "%d/%m/%Y")
    else:
        df["Date_"]=d
df=df.set_index("Date_")
#Borremos la columna unnamed
df=df.drop(columns=["Date","Unnamed: 1"])
df

infoDataframe = {}
#Cantidad de columnas.
infoDataframe['Cantidad Columnas'] = df.shape[1]
#Nombre de las columnas.
infoDataframe['Nombre Columnas'] = ', '.join(df.columns)
#Veamos la cantidad de registros no nan por cada columna.
cuentaColumna = []
for col in df.columns:
    nonan = df[col].count()
    col_count_str = f"{col}: {nonan}"
    cuentaColumna.append(col_count_str)
cadena = ", ".join(cuentaColumna)
infoDataframe['Registro no NAN'] = cadena
#Cantidad de memoria usada
infoDataframe['Memoria Usada'] = df.memory_usage()
#Estadistica básica
media = df.mean()
desviacion = df.std()
maximo = df.max(axis=0)
cadenaEst = ''
for i in range(df.shape[1]-1):
  cadenaEst += f' media col {i}: ' + str(media[i]) + f' desviación col {i}: ' + str(desviacion[i]) + f' maximo {i}:  '+ str(maximo[i])
infoDataframe['Estadistica'] =  cadenaEst
#Finalmente reemplazamos todos los valores NAN por un 'None'.
df.fillna(value='None', inplace= True)
#Veamos el diccionario
infoDataframe

"""#Problema 3

Realizar la lectura del data frame "Crimes_-_2019.csv" asociado a los crimenes que se presentaron en Chicago en el 2019. 


1. Ver la estadistica general del data frame.
2. Elimnar  las columnas PrimaryType, y Date.
3. Transformar la columna Date que es tipo string en una tipo Fecha, use el siguiente metodo de pandas pd.to_datetime(df.Date,format="%m/%d/%Y %I:%M:%S %p")
4. Mostrar los casos totales para cada tipo de crimen de forma ascendente, emplee:
   df.groupby(columna).Date.count()
   
   sort_values()
5. Ordenar los valores por orden alfabetico de Primary type
6. Mostrar de la fila 100 a la 120
6. Realizar una visualización de los datos anteriores.Emplee la libreria  seaborn con un grafico tipo barplot. Ej.
   ax = sns.barplot(x = "contador", y="Primary Type", data = datos)





"""

#Leeamos el archivo.
import pandas as pd
url = 'https://raw.githubusercontent.com/hernansalinas/autogrades/main/Laboratorios_Taller/dataset/Crimes_-_2019.csv'
df = pd.read_csv(url)

#1. Veamos la estadística general del dataframe
media = df.mean();
desviacion = df.std();
maximo = df.max(axis=None);
print(f'media: {media}, desviacion: {desviacion}, máximo: {maximo}');

#2. Eliminar las columnas primary type y date
dfSinDate = df.drop(columns=["Date", "Primary Type"], inplace= False)
dfSinDate

#3. Transformar la columna Date que es tipo string en una tipo Fecha 
##use el siguiente metodo de pandas pd.to_datetime(df.Date,format="%m/%d/%Y %I:%M:%S %p")
from datetime import datetime
df = pd.to_datetime(df.Date,format='%m/%d/%Y %H:%M')

#4. Mostrar los casos totales para cada tipo
## de crimen de forma ascendente, emplee: df.groupby(columna).Date.count()
df.groupby('Primary Type').Date.count().sort_values()

#Ordenar los valores por orden alfabetico de Primary type.
df.sort_values(by='Primary Type', inplace=True)
df

#Mostrar de la fila 100 a la 120
df.iloc[100:120]

#Realizar una visualización de los datos anteriores.
##Emplee la libreria seaborn con un grafico tipo barplot. 
#Ej. ax = sns.barplot(x = "contador", y="Primary Type", data = datos)
import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(14, 8));
sns.barplot(data=df, y = df.groupby('Primary Type').Date.count().values, x=df.groupby('Primary Type').Date.count().index);

"""#Problema 4

1. Leer el dataset country_vaccinations.csv  y filtrar los datos para Colombia
2. Crear un csv con los datos para colombia
3. Realizar una comparacion con los paises latinoamericanos de la cantidad de vacunados.
4. A traves de mascaras determinar el numero de vacunados en el intervalo  [1.5E6, 2.0E6]




Referencias: Puedes consultar la pagina kaggle para estudiar mas acerca de pandas
"""

#1. Leer el dataset 
import pandas as pd
url = 'https://raw.githubusercontent.com/hernansalinas/autogrades/main/Laboratorios_Taller/dataset/country_vaccinations.csv'
df = pd.read_csv(url)
df

#2. Crear un csv con los datos para Colombia.
dfColombia = df[df['country'] == 'Colombia']
csvColombia = dfColombia.to_csv('csvColombia',index=False)

#Realizar una comparación con los países latinoamericanos de la cantidad de vacunados
#Le pedimos a chatgpt que nos haga la lista de todos los paises
paises = ['Argentina','Bolivia', 'Brazil', 'Chile', 'Colombia', 'Costa Rica', 'Cuba', 'Dominican Republic', 'Ecuador', 'El Salvador', 'Guatemala', 'Haiti', 'Honduras', 'Jamaica', 'Mexico', 'Nicaragua', 'Panama', 'Paraguay', 'Peru', 'Puerto Rico', 'Trinidad and Tobago', 'Uruguay', 'Venezuela']
dfLatam = df[df['country'].isin(paises)]
#Hagamos un histograma para comparar los paises
import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(14, 8));
sns.barplot(data=df, y = dfLatam.groupby('country').total_vaccinations.count().values, x=dfLatam.groupby('country').total_vaccinations.count().index);

#A través de mascaras determinar el numero de vacunados en el intervalo [1.5E6, 2.0E6]
cotaInferior = 1.5e6
cotaSuperior = 2.0e6
mascara = (df['people_vaccinated']>= cotaInferior ) & (df['people_vaccinated']<=cotaSuperior)
#Creamos un dataframe con los vacunados en este rango
dfCondicion = df[mascara]
#Agrupamos la cantidad de vacunados por país en este rango
dfCondicion.groupby('country').people_vaccinated.count()